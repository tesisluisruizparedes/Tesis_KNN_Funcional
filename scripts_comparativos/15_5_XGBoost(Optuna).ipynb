{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNIK8RNk+bBPYkjiwgpqRUg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hy9G2TZVCovu","executionInfo":{"status":"ok","timestamp":1747619923205,"user_tz":300,"elapsed":3126787,"user":{"displayName":"TesisLuis Ruiz Paredes","userId":"09818400265379829088"}},"outputId":"e4dcd078-4bbc-44fc-a7fe-82e0b7cfa9b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-05-19 01:06:48,985] A new study created in memory with name: no-name-4efd512a-5961-448e-8acc-ae53ee19431d\n","[I 2025-05-19 01:07:41,629] Trial 0 finished with value: 0.43116273574958264 and parameters: {'n_estimators': 150, 'max_depth': 7, 'learning_rate': 0.2982292719210495, 'subsample': 0.9950784730280301, 'colsample_bytree': 0.9066294903134606}. Best is trial 0 with value: 0.43116273574958264.\n","[I 2025-05-19 01:09:16,175] Trial 1 finished with value: 0.434176654574799 and parameters: {'n_estimators': 258, 'max_depth': 8, 'learning_rate': 0.1639148509367559, 'subsample': 0.7773148498553433, 'colsample_bytree': 0.844587899323772}. Best is trial 1 with value: 0.434176654574799.\n","[I 2025-05-19 01:09:58,188] Trial 2 finished with value: 0.4099533355588319 and parameters: {'n_estimators': 214, 'max_depth': 5, 'learning_rate': 0.12243994322641127, 'subsample': 0.6436534266524245, 'colsample_bytree': 0.6360102329789064}. Best is trial 1 with value: 0.434176654574799.\n","[I 2025-05-19 01:11:29,081] Trial 3 finished with value: 0.42115267804444284 and parameters: {'n_estimators': 257, 'max_depth': 8, 'learning_rate': 0.038000153061225, 'subsample': 0.78266071009112, 'colsample_bytree': 0.782311969047691}. Best is trial 1 with value: 0.434176654574799.\n","[I 2025-05-19 01:12:25,198] Trial 4 finished with value: 0.4225670207028275 and parameters: {'n_estimators': 212, 'max_depth': 7, 'learning_rate': 0.04214990143064062, 'subsample': 0.5936328959176151, 'colsample_bytree': 0.5052913716697028}. Best is trial 1 with value: 0.434176654574799.\n","[I 2025-05-19 01:13:05,837] Trial 5 finished with value: 0.4219504227683554 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.2507552085297275, 'subsample': 0.5286882098087742, 'colsample_bytree': 0.9059796142936691}. Best is trial 1 with value: 0.434176654574799.\n","[I 2025-05-19 01:14:19,193] Trial 6 finished with value: 0.43119757944991316 and parameters: {'n_estimators': 181, 'max_depth': 9, 'learning_rate': 0.22177254779019132, 'subsample': 0.5527873638638038, 'colsample_bytree': 0.5759362023097278}. Best is trial 1 with value: 0.434176654574799.\n","[I 2025-05-19 01:15:05,552] Trial 7 finished with value: 0.42064647507414354 and parameters: {'n_estimators': 150, 'max_depth': 7, 'learning_rate': 0.08671259268627765, 'subsample': 0.600192063508261, 'colsample_bytree': 0.6404161339144264}. Best is trial 1 with value: 0.434176654574799.\n","[I 2025-05-19 01:15:52,608] Trial 8 finished with value: 0.4309649451359808 and parameters: {'n_estimators': 156, 'max_depth': 7, 'learning_rate': 0.2114263502713818, 'subsample': 0.7505641745199642, 'colsample_bytree': 0.8304513366592684}. Best is trial 1 with value: 0.434176654574799.\n","[I 2025-05-19 01:16:20,635] Trial 9 finished with value: 0.3909546831233833 and parameters: {'n_estimators': 188, 'max_depth': 3, 'learning_rate': 0.11489267844775441, 'subsample': 0.8743438508375658, 'colsample_bytree': 0.5399956690940215}. Best is trial 1 with value: 0.434176654574799.\n","[I 2025-05-19 01:19:02,887] Trial 10 finished with value: 0.4412546886941887 and parameters: {'n_estimators': 290, 'max_depth': 10, 'learning_rate': 0.17991048783569247, 'subsample': 0.8630574886427571, 'colsample_bytree': 0.9908525593927564}. Best is trial 10 with value: 0.4412546886941887.\n","[I 2025-05-19 01:21:45,591] Trial 11 finished with value: 0.4380280782143635 and parameters: {'n_estimators': 299, 'max_depth': 10, 'learning_rate': 0.1741414916807393, 'subsample': 0.8775309266186968, 'colsample_bytree': 0.983786023762575}. Best is trial 10 with value: 0.4412546886941887.\n","[I 2025-05-19 01:24:32,309] Trial 12 finished with value: 0.43779898922300725 and parameters: {'n_estimators': 298, 'max_depth': 10, 'learning_rate': 0.17242242406536437, 'subsample': 0.89226903395881, 'colsample_bytree': 0.9828642670223627}. Best is trial 10 with value: 0.4412546886941887.\n","[I 2025-05-19 01:27:16,706] Trial 13 finished with value: 0.4362757416536377 and parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.1965232478720714, 'subsample': 0.878223743548353, 'colsample_bytree': 0.9616424932444209}. Best is trial 10 with value: 0.4412546886941887.\n","[I 2025-05-19 01:28:14,853] Trial 14 finished with value: 0.4197652797163197 and parameters: {'n_estimators': 103, 'max_depth': 9, 'learning_rate': 0.13460912721083543, 'subsample': 0.985578742424029, 'colsample_bytree': 0.9959130962414998}. Best is trial 10 with value: 0.4412546886941887.\n","[I 2025-05-19 01:30:17,308] Trial 15 finished with value: 0.4418645155623272 and parameters: {'n_estimators': 264, 'max_depth': 10, 'learning_rate': 0.2608777433998412, 'subsample': 0.8424780273922209, 'colsample_bytree': 0.7054679327236554}. Best is trial 15 with value: 0.4418645155623272.\n","[I 2025-05-19 01:32:06,948] Trial 16 finished with value: 0.42384579883832957 and parameters: {'n_estimators': 260, 'max_depth': 9, 'learning_rate': 0.29240979444245885, 'subsample': 0.6958845650898481, 'colsample_bytree': 0.7075061911188751}. Best is trial 15 with value: 0.4418645155623272.\n","[I 2025-05-19 01:32:52,069] Trial 17 finished with value: 0.42333039500295255 and parameters: {'n_estimators': 235, 'max_depth': 5, 'learning_rate': 0.2563852502802737, 'subsample': 0.8249003206023213, 'colsample_bytree': 0.7325329575154187}. Best is trial 15 with value: 0.4418645155623272.\n","[I 2025-05-19 01:33:29,142] Trial 18 finished with value: 0.3871417071206268 and parameters: {'n_estimators': 272, 'max_depth': 3, 'learning_rate': 0.2573284244897041, 'subsample': 0.960881232632439, 'colsample_bytree': 0.6835584707783435}. Best is trial 15 with value: 0.4418645155623272.\n","[I 2025-05-19 01:34:50,083] Trial 19 finished with value: 0.4300806124910256 and parameters: {'n_estimators': 238, 'max_depth': 8, 'learning_rate': 0.082052478047885, 'subsample': 0.7051390239870745, 'colsample_bytree': 0.7746561740010123}. Best is trial 15 with value: 0.4418645155623272.\n","[I 2025-05-19 01:37:05,642] Trial 20 finished with value: 0.4448496155964742 and parameters: {'n_estimators': 276, 'max_depth': 10, 'learning_rate': 0.22422907202830034, 'subsample': 0.9394016626803288, 'colsample_bytree': 0.8338246282922288}. Best is trial 20 with value: 0.4448496155964742.\n","[I 2025-05-19 01:39:25,870] Trial 21 finished with value: 0.43396329189595795 and parameters: {'n_estimators': 278, 'max_depth': 10, 'learning_rate': 0.23174347210996654, 'subsample': 0.9385336685334448, 'colsample_bytree': 0.8269145614710453}. Best is trial 20 with value: 0.4448496155964742.\n","[I 2025-05-19 01:41:35,669] Trial 22 finished with value: 0.4342388111838519 and parameters: {'n_estimators': 281, 'max_depth': 9, 'learning_rate': 0.19642190157328115, 'subsample': 0.8228588926041547, 'colsample_bytree': 0.9084558435106651}. Best is trial 20 with value: 0.4448496155964742.\n","[I 2025-05-19 01:43:23,722] Trial 23 finished with value: 0.43203572684146063 and parameters: {'n_estimators': 231, 'max_depth': 10, 'learning_rate': 0.27216499576130415, 'subsample': 0.9304463077852774, 'colsample_bytree': 0.6588686226632362}. Best is trial 20 with value: 0.4448496155964742.\n","[I 2025-05-19 01:45:30,059] Trial 24 finished with value: 0.4395706702110712 and parameters: {'n_estimators': 281, 'max_depth': 9, 'learning_rate': 0.22669851141020952, 'subsample': 0.9184728719738292, 'colsample_bytree': 0.8723636506574081}. Best is trial 20 with value: 0.4448496155964742.\n","[I 2025-05-19 01:47:38,582] Trial 25 finished with value: 0.43938245485074773 and parameters: {'n_estimators': 254, 'max_depth': 10, 'learning_rate': 0.19097179968230682, 'subsample': 0.8299601786482235, 'colsample_bytree': 0.7864227313155341}. Best is trial 20 with value: 0.4448496155964742.\n","[I 2025-05-19 01:48:56,465] Trial 26 finished with value: 0.4404653996059841 and parameters: {'n_estimators': 244, 'max_depth': 8, 'learning_rate': 0.14556668508280704, 'subsample': 0.8407630250661382, 'colsample_bytree': 0.5982042629435099}. Best is trial 20 with value: 0.4448496155964742.\n","[I 2025-05-19 01:50:02,801] Trial 27 finished with value: 0.4311023645795512 and parameters: {'n_estimators': 270, 'max_depth': 6, 'learning_rate': 0.27708768508011195, 'subsample': 0.7816822268602687, 'colsample_bytree': 0.737628208413211}. Best is trial 20 with value: 0.4448496155964742.\n","[I 2025-05-19 01:52:12,502] Trial 28 finished with value: 0.4377848076695816 and parameters: {'n_estimators': 285, 'max_depth': 9, 'learning_rate': 0.23694038680657975, 'subsample': 0.9076360941905728, 'colsample_bytree': 0.9412883008096355}. Best is trial 20 with value: 0.4448496155964742.\n","[I 2025-05-19 01:53:09,000] Trial 29 finished with value: 0.4297716780685885 and parameters: {'n_estimators': 220, 'max_depth': 6, 'learning_rate': 0.287495065737716, 'subsample': 0.9887518283331622, 'colsample_bytree': 0.9187871203014474}. Best is trial 20 with value: 0.4448496155964742.\n","XGBoost Optuna SMOTE + Año: 100%|██████████| 10/10 [05:13<00:00, 31.40s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","✅ Resultados guardados en: /content/drive/MyDrive/Resultados/resultados_comparativos_modelos_turismo.csv\n"]}],"source":["# 🚀 Instalar librerías necesarias\n","!pip install optuna --quiet\n","!pip install xgboost --quiet\n","\n","# 🚗 Montar Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# 📚 Librerías\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import optuna\n","from tqdm import tqdm\n","import os, gc, warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from xgboost import XGBClassifier\n","from imblearn.over_sampling import SMOTE\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import (\n","    accuracy_score, precision_score, recall_score, f1_score,\n","    roc_auc_score, log_loss, roc_curve, precision_recall_curve,\n","    average_precision_score\n",")\n","\n","# 📍 Rutas\n","ruta_base = \"/content/drive/MyDrive/Datos/6_Base_Modelos_Predictivos.parquet\"\n","ruta_resumen = \"/content/drive/MyDrive/Resultados/resultados_comparativos_modelos_turismo.csv\"\n","ruta_roc = \"/content/drive/MyDrive/Resultados/15_7_Curva_ROC_XGB_Optuna_SMOTE_Año.png\"\n","ruta_prc = \"/content/drive/MyDrive/Resultados/15_7_Curva_PRC_XGB_Optuna_SMOTE_Año.png\"\n","\n","# 📦 Cargar base y preparar variables\n","df = pd.read_parquet(ruta_base).drop_duplicates()\n","df = pd.get_dummies(df, columns=[\"Año\", \"DEP\", \"CIIU_Letra\"], drop_first=False)\n","\n","y = df[\"RQ\"]\n","X = df.drop(columns=[\"RQ\", \"NIT\"])\n","X = X.replace([np.inf, -np.inf], 1e6)\n","\n","# ⚙️ Función objetivo para Optuna\n","def objective(trial):\n","    params = {\n","        'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n","        'max_depth': trial.suggest_int('max_depth', 3, 10),\n","        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n","        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n","        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n","        'eval_metric': 'logloss',\n","        'use_label_encoder': False,\n","        'random_state': 42\n","    }\n","\n","    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","    f1_scores = []\n","\n","    for train_idx, test_idx in skf.split(X, y):\n","        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n","        smote = SMOTE(random_state=42)\n","        X_res, y_res = smote.fit_resample(X_train, y_train)\n","\n","        model = XGBClassifier(**params)\n","        model.fit(X_res, y_res)\n","        y_pred = model.predict(X.iloc[test_idx])\n","        f1_scores.append(f1_score(y.iloc[test_idx], y_pred))\n","\n","    return np.mean(f1_scores)\n","\n","# 🔍 Buscar hiperparámetros óptimos\n","study = optuna.create_study(direction=\"maximize\")\n","study.optimize(objective, n_trials=30)\n","\n","best_params = study.best_params\n","best_params.update({\n","    'eval_metric': 'logloss',\n","    'use_label_encoder': False,\n","    'random_state': 42\n","})\n","\n","# 🧠 Entrenamiento final con validación cruzada\n","skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n","resultados, roc_curves, prc_curves = [], [], []\n","loglosses, aucs, y_true_total, y_prob_total = [], [], [], []\n","\n","for train_idx, test_idx in tqdm(skf.split(X, y), total=10, desc=\"XGBoost Optuna SMOTE + Año\"):\n","    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n","    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n","\n","    smote = SMOTE(random_state=42)\n","    X_res, y_res = smote.fit_resample(X_train, y_train)\n","\n","    model = XGBClassifier(**best_params)\n","    model.fit(X_res, y_res)\n","\n","    y_pred = model.predict(X_test)\n","    y_prob = model.predict_proba(X_test)[:, 1]\n","\n","    resultados.append([\n","        accuracy_score(y_test, y_pred),\n","        precision_score(y_test, y_pred),\n","        recall_score(y_test, y_pred),\n","        f1_score(y_test, y_pred)\n","    ])\n","    loglosses.append(log_loss(y_test, y_prob))\n","    aucs.append(roc_auc_score(y_test, y_prob))\n","\n","    fpr, tpr, _ = roc_curve(y_test, y_prob)\n","    precision, recall, _ = precision_recall_curve(y_test, y_prob)\n","    roc_curves.append((fpr, tpr))\n","    prc_curves.append((recall, precision))\n","\n","    y_true_total.extend(y_test)\n","    y_prob_total.extend(y_prob)\n","\n","# 📈 Curva ROC\n","fpr_interp = np.linspace(0, 1, 100)\n","tprs = [np.interp(fpr_interp, fpr, tpr) for fpr, tpr in roc_curves]\n","tpr_mean, tpr_std = np.mean(tprs, axis=0), np.std(tprs, axis=0)\n","\n","plt.figure()\n","plt.plot(fpr_interp, tpr_mean, label=f'ROC promedio (AUC = {np.mean(aucs):.3f})')\n","plt.fill_between(fpr_interp, tpr_mean - tpr_std, tpr_mean + tpr_std, alpha=0.2)\n","plt.plot([0, 1], [0, 1], 'k--')\n","plt.xlabel(\"Falsos Positivos\")\n","plt.ylabel(\"Verdaderos Positivos\")\n","plt.title(\"Curva ROC - XGBoost Optuna + Año\")\n","plt.grid()\n","plt.tight_layout()\n","plt.savefig(ruta_roc)\n","plt.close()\n","\n","# 📈 Curva PRC\n","recall_interp = np.linspace(0, 1, 100)\n","precisions = [np.interp(recall_interp, r[::-1], p[::-1]) for r, p in prc_curves]\n","prec_mean, prec_std = np.mean(precisions, axis=0), np.std(precisions, axis=0)\n","\n","plt.figure()\n","plt.plot(recall_interp, prec_mean, label='PRC promedio')\n","plt.fill_between(recall_interp, prec_mean - prec_std, prec_mean + prec_std, alpha=0.2)\n","plt.xlabel(\"Recall\")\n","plt.ylabel(\"Precision\")\n","plt.title(\"Curva PRC - XGBoost Optuna + Año\")\n","plt.grid()\n","plt.tight_layout()\n","plt.savefig(ruta_prc)\n","plt.close()\n","\n","# 📊 Métricas finales\n","res_np = np.array(resultados)\n","mean = res_np.mean(axis=0)\n","std = res_np.std(axis=0)\n","logl_mean, logl_std = np.mean(loglosses), np.std(loglosses)\n","auc_mean, auc_std = np.mean(aucs), np.std(aucs)\n","\n","# 🧾 Guardar en resumen\n","if os.path.exists(ruta_resumen):\n","    resumen = pd.read_csv(ruta_resumen)\n","    if 'Observación' in resumen.columns:\n","        resumen = resumen.drop(columns='Observación')\n","else:\n","    resumen = pd.DataFrame(columns=[\n","        'Base', 'Modelo', 'Naturaleza', 'Temporalidad', 'Tipo de aprendizaje',\n","        'Accuracy', 'Desv. Accuracy', 'Precision', 'Desv. Precision',\n","        'Recall', 'Desv. Recall', 'F1-score promedio', 'Desviación F1',\n","        'AUC', 'Desv. AUC', 'LogLoss', 'Desv. LogLoss',\n","        'Top 1 variable', 'Top 2 variable', 'Top 3 variable'\n","    ])\n","\n","model_final = XGBClassifier(**best_params)\n","model_final.fit(X, y)\n","importancias = pd.Series(model_final.feature_importances_, index=X.columns)\n","top_vars = importancias.sort_values(ascending=False).head(3).index.tolist()\n","top1, top2, top3 = (top_vars + [None]*3)[:3]\n","\n","idx = resumen[\n","    (resumen['Base'] == 'Turismo') &\n","    (resumen['Modelo'] == 'XGBoost (Optuna + SMOTE + Año)')\n","].index\n","idx = idx[0] if len(idx) > 0 else len(resumen)\n","\n","resumen.loc[idx] = [\n","    'Turismo', 'XGBoost (Optuna + SMOTE + Año)', 'Avanzado', 'Estática', 'Supervisado',\n","    round(mean[0], 4), round(std[0], 4),\n","    round(mean[1], 4), round(std[1], 4),\n","    round(mean[2], 4), round(std[2], 4),\n","    round(mean[3], 4), f\"±{std[3]:.4f}\",\n","    round(auc_mean, 4), round(auc_std, 4),\n","    round(logl_mean, 4), round(logl_std, 4),\n","    top1, top2, top3\n","]\n","\n","resumen.to_csv(ruta_resumen, index=False)\n","print(f\"\\n✅ Resultados guardados en: {ruta_resumen}\")\n"]}]}